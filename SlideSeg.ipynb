{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SlideSeg\n",
    "\n",
    "Spawar, Systems Center Pacific <br>\n",
    "Created August 1, 2017 <br>\n",
    "Author: Brendan Crabb <brendancrabb8388@pointloma.edu> \n",
    "<hr>\n",
    "\n",
    "Welcome to SlideSeg, a python script that allows you to segment whole slide images into usable image\n",
    "chips for deep learning. Image masks for each chip are generated from associated markup and annotation files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "[User Guide](#user-guide)\n",
    "\n",
    "1.    [Dependencies](#1.)  \n",
    "2.    [Anaconda Environment](#2.)  \n",
    "      2.1 [Creating environment from .yml file](#2.1)  \n",
    "      2.2 [Change Jupyter Notebook startup folder (Windows)](#2.2)  \n",
    "      2.3 [Change Jupyter Notebook startup folder (OS X)](#2.3)  \n",
    "      2.4 [Jupyter Kernel Selection](#2.4)\n",
    "3.     [Setup](#3.)  \n",
    "      3.1 [Supported Formats](#3.1)  \n",
    "      3.2 [Parameters](#3.2)  \n",
    "      3.3 [Annotation Key](#3.3)  \n",
    "5.     [Output](#5.)  \n",
    "      5.1 [Image_Chips](#5.1)  \n",
    "      5.2 [Image_Masks](#5.2)  \n",
    "      5.3 [Text Files](#5.3)  \n",
    "6.     [Run](#6.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Guide <a class =\"anchor\" id=\"user-guide\"></a>\n",
    "\n",
    "### 1. Dependencies <a class =\"anchor\" id=\"1.\"></a>\n",
    "\n",
    "SlideSeg runs on Python 2.7 and depends on the following libraries: <br>\n",
    "\n",
    " * openslide 1.1.1 <br>\n",
    " * tqdm 4.15.0 <br>\n",
    " * cv2 3.2.0 <br>\n",
    " * numpy <br>\n",
    " * pexif 0.15 <br>\n",
    "\n",
    "The libraries can be installed using the following sources: <br>\n",
    " * openslide:  pip install openslide-python <br>\n",
    " * tqdm:       conda install -c conda-forge tqdm <br>\n",
    " * numpy:      conda install -c anaconda numpy <br>\n",
    " * cv2:        pip install opencv-python <br>\n",
    " * pexif:      pip install pexif<br>\n",
    " \n",
    "If you are using the preconfigured SlideSeg anaconda environment, these dependencies will already be installed.  <br>\n",
    "\n",
    "### 2. Anaconda Environment <a class =\"anchor\" id=\"2.\"></a>\n",
    "\n",
    "Make sure anaconda is installed. The SlideSeg environment has an Ipython kernel with all of the necessary packages already installed; however, conda support for jupyter notebooks is needed to switch kernels. This support is available through conda itself and can be enabled by issuing the following command:\n",
    "\n",
    "<code>conda install nb_conda </code>\n",
    "\n",
    "##### 2.1 Creating environment from .yml file <a class =\"anchor\" id=\"2.1\"></a>\n",
    "Copy the environment_slideseg.yml file to the anaconda directory,  .../anaconda/scripts/. In the same directory, issue the following command to create the anaconda environment from the file:\n",
    "\n",
    "<code>conda env create -f environment_slideseg.yml </code>\n",
    "\n",
    "Creating the environment might take a few minutes. Once finished, issue the following command to activate the environment:\n",
    "\n",
    "* Windows: <code>activate SlideSeg</code>\n",
    "* macOS and Linux: <code>source activate SlideSeg</code>\n",
    "\n",
    "If the environment was activated successfully, you should see (SlideSeg) at the beggining of the command prompt. This will set the SlideSeg kernel as your default kernel when running jupyter. \n",
    "\n",
    "The Jupyter Notebook App can be launched by clicking on the Jupyter Notebook icon installed by Anaconda in the start menu (Windows) or by typing in the terminal (cmd on Windows): \n",
    "\n",
    "<code>jupyter notebook</code>\n",
    "\n",
    "This will launch a new browser window showing the Notebook Dashboard.  When started, the Jupyter Notebook app can only access files within its start-up folder.  If you stored the SlideSeg notebook documents in a subfolder of your user folder, no configuration is necessary.  Otherwise, you need to change your Jupyter Notebook App start-up folder.  \n",
    "\n",
    "#####  2.2 Change Jupyter Notebook startup folder (Windows) <a class =\"anchor\" id=\"2.2\"></a>\n",
    "\n",
    "* Copy the *Jupyter Notebook* launcher from the menu to the desktop. <br>\n",
    "* Right click on the new launcher, select properties, and change the *Target field*, change %USERPROFILE% to the full path of the folder which will contain all the notebooks. <br>\n",
    "* Double-click on the *Jupyter Notebook* desktop launcher (icon shows [IPy]) to start the Jupyter Notebook App, which will open in a new browser window (or tab). Note also that a secondary terminal window (used only for error logging and for shut down) will be also opened. If only the terminal starts, try opening this address with your browser: http://localhost:8888/. <br>\n",
    "\n",
    "##### 2.3 Change Jupyter Notebook startup folder (OS X) <a class =\"anchor\" id=\"2.3\"></a>\n",
    "To launch Jupyter Notebook App:\n",
    "\n",
    "* Click on spotlight, type terminal to open a terminal window.\n",
    "* Enter the startup folder by typing cd /some_folder_name.\n",
    "* Type jupyter notebook to launch the Jupyter Notebook App (it will appear in a new browser window or tab). <br>\n",
    "\n",
    "##### 2.4 Jupyter Kernel Selection <a class =\"anchor\" id = \"2.4\"></a>\n",
    "After launching the Jupyter Notebook App, navigate to the SlideSeg notebook and click on its name to open in a new browser tab. In the upper right corner, you should see  Python [conda env:SlideSeg].  If not, click on Kernel> Change Kernel> and change your current kernel to Python [conda env:SlideSeg]. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setup <a class =\"anchor\" id=\"3.\"></a>\n",
    "\n",
    "   Copy all of the slide images into the images folder in the main project directory. Copy the markup and annotation files (in .xml format) into the xml folder in the main project directory. It is important that the annotation files have the same file name as the slide they are associated with. <br>\n",
    "   \n",
    "##### 3.1 Supported Formats <a class =\"anchor\" id=\"3.1\"></a>\n",
    "\n",
    "SlideSeg can read virtual slides in the following formats: <br>\n",
    "   \n",
    "  * Aperio (.svs, .tif) <br>\n",
    "  * Hamamatsu (.ndpi, .vms, .vmu) <br>\n",
    "  * Leica (.scn) <br>\n",
    "  * MIRAX (.mrxs) <br>\n",
    "  * Philips (.tiff) <br>\n",
    "  * Sakura (.svslide) <br>\n",
    "  * Trestle (.tif) <br>\n",
    "  * Ventana (.bif, .tif) <br>\n",
    "  * Generic tile TIFF (.tif) <br>\n",
    "\n",
    "SlideSeg can read annotations in the following formats: <br>\n",
    "  * XML (.xml) <br>\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2 Parameters <a class =\"anchor\" id=\"3.2\"></a>\n",
    "  \n",
    " SlideSeg depends on the following parameters:\n",
    " \n",
    "<p style=\"margin-left: 40px\">\n",
    "<b>single_slide:</b> True if using one image only, False if a folder of images is being used <br>\n",
    "\n",
    "<b>slide_path:</b> Path to the folder of slide images <br>\n",
    "\n",
    "<b>xml_path:</b> Path to the folder of xml files <br>\n",
    "\n",
    "<b>output_dir:</b> Path to the output folder where image_chips, image_masks, and text_files will be saved <br>\n",
    "\n",
    "<b>format:</b> Output format of the image_chips and image_masks (png or jpg only) <br>\n",
    "\n",
    "<b>quality:</b> Output quality: JPEG compression if output format is 'jpg' (100 recommended,jpg compression artifacts will distort image segmentation) <br>\n",
    "\n",
    "<b>size:</b> Size of image_chips and image_masks in pixels <br>\n",
    "\n",
    "<b>overlap:</b> Pixel overlap between image chips <br>\n",
    "\n",
    "<b>key:</b> The text file containing annotation keys and color codes <br>\n",
    "\n",
    "<b>save_all:</b> True saves every image_chip, False only saves chips containing an annotated pixel <br>\n",
    "\n",
    "<b>save_ratio:</b> Ratio of image_chips containing annotations to image_chips not containing annotations (use 'inf' if only annotated chips are desired; only applicable if save_all == False <br>\n",
    "\n",
    "<b>printout:</b> Suppress or print outputs.  If printout == 1, the filename will be printed to the terminal if an image chip is saved. If printout == 0, the print function is suppressed <br>\n",
    "\n",
    "<b>tags:</b> Write annotation key tags to image xmp metadata.  If tags == 1, tags are enabled.  If tags == 0, the tags are disabled. <br>\n",
    "</p>\n",
    "\n",
    "These parameters can be specified in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Parameters = {\n",
    "    'single_slide': False,\n",
    "    'slide_path': 'images/',\n",
    "    'xml_path': 'xml/',\n",
    "    'output_dir': 'output/',\n",
    "    'format': 'jpg',\n",
    "    'quality': 100,\n",
    "    'size': 128,\n",
    "    'overlap': 1,\n",
    "    'key': 'Annotation_Key.txt',\n",
    "    'save_all': False,\n",
    "    'save_ratio': 'inf',\n",
    "    'print': 0,\n",
    "    'tags': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "   \n",
    "##### 3.3 Annotation Key <a class =\"anchor\" id=\"3.3\"></a>\n",
    "\n",
    "   The main directory should already contain an Annotation_Key.txt file. If no Annotation_Key file is present, one will be generated automatically from the annotation files in the xml folder.<br>\n",
    "\n",
    "   The Annotation_Key file contains every annotation key with its associated color code. In all image masks, annotations with that key will have the specified pixel value.  If an unknown key is encountered, it will be given a pixel value and added to the Annotation_Key automatically. <br>\n",
    "   \n",
    "   the AnnotationKey class generates and loads color codes from an annotation key. It contains the following functions: <br>\n",
    "   \n",
    "<code><b>class AnnotationKey</b>(object)</code>\n",
    "   \n",
    "<code>\\__init\\__(self, annotation_key)</code>\n",
    "> Generates and loads color codes form annotation key <br>\n",
    "\n",
    "> :param annotation_key:\n",
    "   \n",
    "<code>load_keys(self)</code> <br>\n",
    "\n",
    "> Opens annotation_key file and loads keys and color codes <br>\n",
    "\n",
    "> :return: color codes <br>\n",
    "\n",
    "<code>add_keys(self, key)</code> <br>\n",
    "\n",
    "> Adds new key and color_code to annotaiton key <br>\n",
    "\n",
    "> :param key: The annotation to be added <br>\n",
    "> :return: updated annotation key file <br>\n",
    "\n",
    "<code>write_annotation_keys(self, annotations)</code> <br>\n",
    "\n",
    "> Writes annotation keys and color codes to text file <br>\n",
    "\n",
    "> :param annotations: Dictionary of annotation keys and color codes <br>\n",
    "> :return: .txt file with annotation keys <br>\n",
    "\n",
    "<code>generate_key(self, path)</code> <br>\n",
    "\n",
    "> Generates annotation_key from folder of xml files <br>\n",
    "\n",
    "> :param path: Directory containing xml files <br>\n",
    "> :return: annotation_key file <br>\n",
    "\n",
    "The cell below will import the AnnotationKey class from the python script, chip_generator.py, as well as some other useful modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chip_generator import AnnotationKey\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to display the Annotation Key. The first function generates a new annotation keys from the folder 'xml/' if no annotation key exists.  The second function displays the key in the notebook. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.isfile('Annotation_Key.txt'):\n",
    "    AnnotationKey('Annotation_Key.txt').generate_key('xml/')\n",
    "\n",
    "file = open('Annotation_Key.txt', 'r')\n",
    "for line in file:\n",
    "    sys.stdout.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Output <a class =\"anchor\" id=\"5.\"></a>\n",
    "\n",
    "##### 5.1 Image<span>&#95;</span>chips <a class =\"anchor\" id=\"5.1\"></a>\n",
    "Every generated image chip will be saved in the _output/image<span>&#95;</span>chips_ folder. The chips are saved with the naming convention of _slide filename<span>&#95;</span>level number<span>&#95;</span>row<span>&#95;</span>column.format_. If the chip contains an area that was annotated and the tags are enabled, it will have an associated tag (under the Subject category) with the annotation key. If the image chip does not contain annotations, the 'NONE' tag will be added. To view these tags, switch to details view and click display 'Subject' in the explorer. The files can be sorted according to their tags. Unfortunately, these tags will only be available if the output format is .jpg. <br>\n",
    "\n",
    "The OutputSave class saves both the image chips and image masks, as well as attaching exif metadata to the images. It contains the following functions:\n",
    "\n",
    "<code><b>class OutputSave</b>(object)</code>\n",
    "\n",
    "<code>\\__init\\__(self, keys, print_save, tags)</code> <br>\n",
    "\n",
    "> Save image chips and image masks\n",
    "\n",
    "> :param keys: <br>\n",
    "> :param print_save: <br>\n",
    "> :param tags: <br>\n",
    "\n",
    "<code>ensure_dir(self, directory)</code> <br>\n",
    "\n",
    "> Ensures the existence of a directory <br>\n",
    "\n",
    "> :param dest: Directory to ensure. <br>\n",
    "> :return: new directory if it did not previously exist. <br>\n",
    "\n",
    "<code>attach_tages(self)</code> <br>\n",
    "\n",
    "> Attaches image tags to metadata of chips and masks <br>\n",
    "\n",
    "> :param path: file to attach tags to. <br>\n",
    "> :return: JPG with metadata tags<br>\n",
    "\n",
    "<code>save_chip(self, chip, path, quality)</code> <br>\n",
    "\n",
    "> Saves the image chips <br>\n",
    "\n",
    "> :param chip: the slide image chip to save<br>\n",
    "> :param path: the full path to the chip<br>\n",
    "> :param quality: the output quality<br>\n",
    "\n",
    "<code>save_mask(self, mask, path)</code><br>\n",
    "\n",
    "> Saves the image mask <br>\n",
    "\n",
    "> :param mask: the image mask to save<br>\n",
    "> :param path: the complete path for the mask<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main functionality of SlideSeg is performed by the ChipGenerator class. This class takes all of the inputs specified in parameters and uses it to generate image chips and image masks. It contains the following functions:\n",
    "\n",
    "<code><b>class ChipGenerator</b>(object)</code>\n",
    "\n",
    "<code>\\__init\\__(self, params)</code> <br>\n",
    "\n",
    "> Generates image chips and masks from whole slides <br>\n",
    "\n",
    "> :param params: the parameters specified in the parameters file\n",
    " \n",
    "<code>open_slide(self, filename)</code> <br>\n",
    "\n",
    "> Opens a whole slide image <br>\n",
    "\n",
    "> :param filename: Slide image name. <br>\n",
    "> :return: slide image, levels, and dimensions <br>\n",
    "\n",
    "<code>curate_mask(self, mask, scale_width, scale_height)</code> <br>\n",
    "\n",
    "> Resize and pad annotation mask if necessary <br>\n",
    "\n",
    "> :param mask: <br>\n",
    "> :param scale_width: <br>\n",
    "> :param scale_height: <br>\n",
    "> :return: curated annotation mask <br>\n",
    "\n",
    "<code>get_chips(self, levels, dims, mask, annotations, filename, suffix)</code> <br>\n",
    "\n",
    "> Finds chip locations that should be loaded and saved. <br>\n",
    "\n",
    "> :param levels: levels in whole slide image <br>\n",
    "> :param dims: dimension of whole slide image <br>\n",
    "> :param mask: annotation mask for slide image <br>\n",
    "> :param annotations: dictionary of annotations in image <br>\n",
    "> :param filename: slide image filename <br>\n",
    "> :param suffix: output format for saving. <br>\n",
    "> :return: chip_dict. Dictionary of chip names, level, col, row, and scale <br>\n",
    "> :return: image_dict. Dictionary of annotations and chips with those annotations <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.2 Image<span>&#95;</span>masks <a class =\"anchor\" id=\"5.2\"></a>\n",
    "An image mask for each image chip is saved in the _output/image<span>&#95;</span>masks folder_. The mask has the same name as the image chip it is associated with. Furthermore, these masks will have the same tags, allowing you to sort by annotation type. <br>\n",
    "\n",
    "The class AnnotationMask handles the generation of an annotation mask from xml files. It contains the following functions: <br>\n",
    "\n",
    "<code><b>class AnnotationMask</b>(object)</code>\n",
    "\n",
    "<code>\\__init\\__(self, xml_filename, xml_path, size)</code> <br>\n",
    "\n",
    "> Returns vertex points for annotations in xml file with their assigned keys <br>\n",
    "\n",
    "> :param xml_filename: The xml file that contains the annotations <br>\n",
    "> :param xml_path: Path to the xml file that contains the annotations <br>\n",
    "> :param size: Size of corresponding slide image <br>  \n",
    "\n",
    "<code>annotations(self)</code> <br>\n",
    "\n",
    "> Reads xml file and makes annotation mask for entire slide image <br>\n",
    "\n",
    "> :return: annotation mask <br>\n",
    "> :return: dictionary of annotation keys and color codes<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3 Text Files <a class =\"anchor\" id=\"5.3\"></a>\n",
    "A text file with details about annotations and image chips will also be saved to _output/textfiles_. For each slide image, this text file will contain a list of all annotation keys present in the image. For each annotation key, a list of every image chip/mask containing that specific key is also recorded in this file. <br>\n",
    "\n",
    "The TextOutput class generates these .txt files. it contains the following functions: <br>\n",
    "\n",
    "<code><b>class TextOutput</b>(object)</code>\n",
    "\n",
    "<code>\\__init\\__(self, filename, annotations)</code> <br>\n",
    "\n",
    "> Generates .txt file with image and annotation information <br>\n",
    "\n",
    "> :param filename: filename of corresponding slide image <br>\n",
    "> :param annotations: annotations contained in the slide image <br>\n",
    "\n",
    "<code>write_keys(self)</code> <br>\n",
    "\n",
    "> Writes each annotation key to the output text file. <br>\n",
    "\n",
    "<code>write_key_img_list(self)</code> <br>\n",
    "\n",
    "> Writes list of images containing each annotation key in the output .txt file<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Run <a class =\"anchor\" id=\"6.\"></a>\n",
    "\n",
    "To execute SlideSeg, simply run the jupyter notebook cells below. Alternatively, you can run the python script 'main.py'. Make sure that you defined the [Parameters](#3.2) above. If the python script is used, the parameters are specified in the Parameters.txt file. <br>\n",
    "\n",
    "To get started, run the cell below to make sure all of the necessary modules are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chip_test import ChipGenerator, AnnotationMask, OutputSave, TextOutput\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell defines a function <code>run(parameters, filename)</code> that generates image chips and masks from the slide image and xml file specified by filename. This function uses classes and functions defined in chip_generator.py in order to open the slide image, generate an annotation mask, find regions of interest, and save chip data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run(parameters, filename):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates image chips from a whole slide image.\n",
    "    :param filename:\n",
    "    :param parameters:\n",
    "    :return: image chips and masks.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Open slide\n",
    "    osr, levels, dims = ChipGenerator(parameters).open_slide(filename)\n",
    "    size = (int(dims[0][0]), int(dims[0][1]))\n",
    "\n",
    "    # Annotation Mask\n",
    "    xml_file = filename.rstrip(\".svs\")\n",
    "    xml_file = xml_file + \".xml\"\n",
    "\n",
    "    print('loading annotation data from {0}/{1}'.format(parameters[\"xml_path\"], xml_file))\n",
    "    mask, annotations = AnnotationMask(xml_file, parameters[\"xml_path\"], size).annotations()\n",
    "\n",
    "    # Define output directory\n",
    "    output_directory_chip = '{0}image_chips/'.format(parameters[\"output_dir\"])\n",
    "    output_directory_mask = '{0}image_mask/'.format(parameters[\"output_dir\"])\n",
    "\n",
    "    # Output formatting check\n",
    "    if parameters[\"format\"].lower() == 'jpg':\n",
    "        suffix = parameters[\"format\"]\n",
    "        parameters[\"format\"] = 'JPEG'\n",
    "\n",
    "    elif parameters[\"format\"].lower() == 'jpeg':\n",
    "        parameters[\"format\"] = parameters[\"format\"].upper()\n",
    "        suffix = 'jpg'\n",
    "\n",
    "    else:\n",
    "        parameters[\"format\"] = parameters[\"format\"].upper()\n",
    "        suffix = parameters[\"format\"].lower()\n",
    "\n",
    "    # Find chip data/locations to be saved\n",
    "    chip_dictionary, image_dict = ChipGenerator(parameters).get_chips(levels, dims, mask, annotations, filename, suffix)\n",
    "\n",
    "    # Save chips and masks\n",
    "    print('Saving chips... {0} chips'.format(len(chip_dictionary)))\n",
    "\n",
    "    for filename, value in tqdm.tqdm(chip_dictionary.iteritems()):\n",
    "        keys = value[0]\n",
    "        i = value[1]\n",
    "        col = value[2]\n",
    "        row = value[3]\n",
    "        scale_factor_width = value[4]\n",
    "        scale_factor_height = value[5]\n",
    "\n",
    "        # load chip region from slide image\n",
    "        img = osr.read_region([int(col * scale_factor_width), int(row * scale_factor_height)], i,\n",
    "                              [int(parameters[\"size\"]), int(parameters[\"size\"])]).convert('RGB')\n",
    "\n",
    "        # load image mask and curate\n",
    "        img_mask = mask[int(row * scale_factor_height):int((row + int(parameters[\"size\"])) * scale_factor_height),\n",
    "                   int(col * scale_factor_width):int((col + int(parameters[\"size\"])) * scale_factor_width)]\n",
    "\n",
    "        img_mask = ChipGenerator(parameters).curate_mask(img_mask, scale_factor_width, scale_factor_height)\n",
    "\n",
    "        # save the image chip and image mask\n",
    "        print('Saving chips... {0} chips'.format(len(chip_dictionary)))\n",
    "\n",
    "        path_chip = output_directory_chip + filename\n",
    "        path_mask = output_directory_mask + filename\n",
    "\n",
    "        OutputSave(keys, int(parameters[\"print\"]), int(parameters[\"tags\"])).save_chip(img, path_chip,\n",
    "                                                                                      int(parameters[\"quality\"]))\n",
    "        OutputSave(keys, int(parameters[\"print\"]), int(parameters[\"tags\"])).save_mask(img_mask, path_mask)\n",
    "\n",
    "    # Make text output of Annotation Data\n",
    "    if int(parameters[\"print\"]) == 1:\n",
    "        print('Updating txt file details...')\n",
    "\n",
    "    TextOutput(xml_file, annotations).write_keys()\n",
    "    TextOutput(xml_file, image_dict).write_key_img_list()\n",
    "\n",
    "    if int(parameters[\"print\"]) == 1:\n",
    "        print('txt file details updated')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imported the necessary modules and defined the function <code>run()</code>, we can execute SlideSeg by running the cell below, which simply passes the parameter and filename information to <code>run()</code>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('running __main__ with parameters: {0}'.format(Parameters))\n",
    "\n",
    "if Parameters[\"single_slide\"] is True:\n",
    "    path, filename = os.path.split(Parameters[\"slide_path\"])\n",
    "    xpath, xml_filename = os.path.split(Parameters[\"xml_path\"])\n",
    "    Parameters[\"slide_path\"] = path\n",
    "    Parameters[\"xml_path\"] = xpath\n",
    "\n",
    "    print('loading {0}'.format(filename))\n",
    "    run(Parameters, filename)\n",
    "\n",
    "else:\n",
    "    for filename in os.listdir(Parameters[\"slide_path\"]):\n",
    "        run(Parameters, filename)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda env:SlideSeg_yml]",
   "language": "python",
   "name": "conda-env-SlideSeg_yml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
